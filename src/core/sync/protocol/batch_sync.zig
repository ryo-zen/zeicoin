// batch_sync.zig - ZSP-001 Compliant Batch Synchronization Protocol
// Primary synchronization implementation for ZeiCoin blockchain
// 
// This implements the ZSP-001 specification for high-performance batch block
// synchronization with up to 50x performance improvement over single-block sync.
//
// Key Features:
// - Batch downloads of 50 blocks per request (optimal network efficiency)
// - Up to 3 concurrent batches (150 blocks in pipeline)
// - Height-based requests using 0xDEADBEEF encoding for backward compatibility  
// - Out-of-order block handling with sequential processing queue
// - Automatic peer failover and retry logic with exponential backoff
// - Progress tracking and resume capability after interruption
//
// Architecture:
// - BatchSyncProtocol: Main sync coordinator
// - BatchTracker: Manages active batch requests and timeouts
// - PendingQueue: Out-of-order block storage for sequential processing
// - SyncMetrics: Performance monitoring and reporting

const std = @import("std");
const print = std.debug.print;

const types = @import("../../types/types.zig");
const net = @import("../../network/peer.zig");
const util = @import("../../util/util.zig");
const sequential = @import("sequential_sync.zig");

// Type aliases for clarity
const Block = types.Block;
const Hash = types.Hash;
const Peer = net.Peer;
const Allocator = std.mem.Allocator;

// ============================================================================
// ZSP-001 CONSTANTS AND CONFIGURATION
// ============================================================================

/// ZSP-001 magic marker for height-encoded block requests
/// Used in first 4 bytes of hash to signal height-based request
const HEIGHT_REQUEST_MAGIC: u32 = 0xDEADBEEF;

/// ZSP-001 batch configuration constants
const BATCH_CONFIG = struct {
    /// Optimal batch size for network efficiency (ZSP-001 recommended)
    const BATCH_SIZE: u32 = 50;
    
    /// Maximum concurrent batches for performance balancing
    const MAX_CONCURRENT_BATCHES: u32 = 3;
    
    /// Maximum pending blocks in out-of-order queue
    const MAX_PENDING_BLOCKS: u32 = 150; // 3 batches Ã— 50 blocks
    
    /// Batch request timeout in seconds
    const BATCH_TIMEOUT_SECONDS: i64 = 60;
    
    /// Stall detection timeout (no progress)
    const STALL_TIMEOUT_SECONDS: i64 = 120;
    
    /// Maximum retry attempts per batch
    const MAX_BATCH_RETRIES: u32 = 3;
    
    /// Progress reporting interval in seconds
    const PROGRESS_REPORT_INTERVAL: i64 = 5;
};

// ============================================================================
// ZSP-001 DATA STRUCTURES
// ============================================================================

/// Batch request tracking structure
/// Manages individual batch download requests with timeout and retry logic
const BatchRequest = struct {
    /// Starting block height for this batch
    start_height: u32,
    
    /// Number of blocks in this batch (may be less than BATCH_SIZE for final batch)
    batch_size: u32,
    
    /// Peer handling this batch request
    peer: *Peer,
    
    /// Timestamp when request was sent (for timeout detection)
    timestamp: i64,
    
    /// Number of retry attempts for this batch
    retry_count: u32,
    
    /// Initialize a new batch request
    pub fn init(start_height: u32, batch_size: u32, peer: *Peer) BatchRequest {
        return .{
            .start_height = start_height,
            .batch_size = batch_size,
            .peer = peer,
            .timestamp = util.getTime(),
            .retry_count = 0,
        };
    }
    
    /// Check if this batch request has timed out
    pub fn isTimedOut(self: *const BatchRequest) bool {
        const elapsed = util.getTime() - self.timestamp;
        return elapsed > BATCH_CONFIG.BATCH_TIMEOUT_SECONDS;
    }
    
    /// Get human-readable description of this batch
    pub fn describe(self: *const BatchRequest, buf: []u8) []const u8 {
        return std.fmt.bufPrint(buf, "heights {}-{} ({} blocks)", .{
            self.start_height,
            self.start_height + self.batch_size - 1,
            self.batch_size,
        }) catch "batch description error";
    }
};

/// Batch tracking manager
/// Coordinates multiple concurrent batch requests and handles timeouts
const BatchTracker = struct {
    /// Active batch requests indexed by start height
    active_batches: std.AutoHashMap(u32, BatchRequest),
    
    /// Next batch starting height to request
    next_batch_start: u32,
    
    /// Highest height that has been fully processed
    completed_height: u32,
    
    /// Allocator for internal data structures
    allocator: Allocator,
    
    pub fn init(allocator: Allocator) BatchTracker {
        return .{
            .active_batches = std.AutoHashMap(u32, BatchRequest).init(allocator),
            .next_batch_start = 0,
            .completed_height = 0,
            .allocator = allocator,
        };
    }
    
    pub fn deinit(self: *BatchTracker) void {
        self.active_batches.deinit();
    }
    
    /// Add a new active batch request
    pub fn addBatch(self: *BatchTracker, batch: BatchRequest) !void {
        try self.active_batches.put(batch.start_height, batch);
        
        var buf: [64]u8 = [_]u8{0} ** 64;
        print("ğŸ“Š [BATCH TRACKER] Added batch: {s} (total active: {})\n", .{
            batch.describe(&buf),
            self.active_batches.count(),
        });
    }
    
    /// Remove a completed batch request
    pub fn removeBatch(self: *BatchTracker, start_height: u32) bool {
        const removed = self.active_batches.remove(start_height);
        
        if (removed) {
            print("ğŸ“Š [BATCH TRACKER] Removed batch starting at height {} (remaining: {})\n", .{
                start_height,
                self.active_batches.count(),
            });
        }
        
        return removed;
    }
    
    /// Get all timed-out batches for retry
    pub fn getTimedOutBatches(self: *BatchTracker, allocator: Allocator) !std.ArrayList(BatchRequest) {
        var timed_out = std.ArrayList(BatchRequest).init(allocator);
        
        var iter = self.active_batches.iterator();
        while (iter.next()) |entry| {
            if (entry.value_ptr.isTimedOut()) {
                try timed_out.append(entry.value_ptr.*);
                print("â° [BATCH TRACKER] Batch timeout detected: {s}\n", .{
                    entry.value_ptr.describe(&[_]u8{0} ** 64)
                });
            }
        }
        
        return timed_out;
    }
    
    /// Check if we can request more batches (under concurrent limit)
    pub fn canRequestMoreBatches(self: *const BatchTracker) bool {
        return self.active_batches.count() < BATCH_CONFIG.MAX_CONCURRENT_BATCHES;
    }
    
    /// Get status for debugging and monitoring
    pub fn getStatus(self: *const BatchTracker) void {
        print("ğŸ“Š [BATCH TRACKER] Status: {} active batches, next: {}, completed: {}\n", .{
            self.active_batches.count(),
            self.next_batch_start,
            self.completed_height,
        });
    }
};

/// Out-of-order block queue for sequential processing
/// Stores blocks that arrive out of order until they can be processed sequentially
const PendingQueue = struct {
    /// Blocks waiting for sequential processing, indexed by height
    blocks: std.AutoHashMap(u32, Block),
    
    /// Maximum capacity to prevent memory exhaustion
    capacity: u32,
    
    /// Allocator for internal data structures
    allocator: Allocator,
    
    pub fn init(allocator: Allocator) PendingQueue {
        return .{
            .blocks = std.AutoHashMap(u32, Block).init(allocator),
            .capacity = BATCH_CONFIG.MAX_PENDING_BLOCKS,
            .allocator = allocator,
        };
    }
    
    pub fn deinit(self: *PendingQueue) void {
        // Clean up any remaining blocks
        var iter = self.blocks.iterator();
        while (iter.next()) |entry| {
            entry.value_ptr.deinit(self.allocator);
        }
        self.blocks.deinit();
    }
    
    /// Add a block to the pending queue
    pub fn addBlock(self: *PendingQueue, height: u32, block: Block) !void {
        // Check capacity limits
        if (self.blocks.count() >= self.capacity) {
            print("âš ï¸ [PENDING QUEUE] At capacity ({}), rejecting block {}\n", .{
                self.capacity, height
            });
            return error.QueueAtCapacity;
        }
        
        // Store the block
        try self.blocks.put(height, block);
        
        print("ğŸ“¥ [PENDING QUEUE] Added block {} (queue size: {})\n", .{
            height, self.blocks.count()
        });
    }
    
    /// Get the next sequential block if available
    pub fn getNextBlock(self: *PendingQueue, expected_height: u32) ?Block {
        if (self.blocks.get(expected_height)) |block| {
            _ = self.blocks.remove(expected_height);
            
            print("ğŸ“¤ [PENDING QUEUE] Retrieved block {} (queue size: {})\n", .{
                expected_height, self.blocks.count()
            });
            
            return block;
        }
        
        return null;
    }
    
    /// Check if queue contains a specific block
    pub fn hasBlock(self: *const PendingQueue, height: u32) bool {
        return self.blocks.contains(height);
    }
    
    /// Get current queue size for monitoring
    pub fn size(self: *const PendingQueue) u32 {
        return @intCast(self.blocks.count());
    }
    
    /// Get status for debugging
    pub fn getStatus(self: *const PendingQueue) void {
        print("ğŸ“Š [PENDING QUEUE] Status: {}/{} blocks, heights: ", .{
            self.blocks.count(), self.capacity
        });
        
        var iter = self.blocks.keyIterator();
        var count: usize = 0;
        while (iter.next()) |height| {
            if (count > 0) print(", ", .{});
            print("{}", .{height.*});
            count += 1;
            if (count >= 10) {
                print("...", .{});
                break;
            }
        }
        print("\n", .{});
    }
};

/// Synchronization metrics and performance monitoring
/// Tracks sync performance for optimization and debugging
const SyncMetrics = struct {
    /// Total blocks downloaded in this sync session
    blocks_downloaded: u32,
    
    /// Total bytes transferred
    bytes_downloaded: u64,
    
    /// Sync session start time
    start_time: i64,
    
    /// Last progress report time
    last_progress_report: i64,
    
    /// Number of batch retries performed
    total_retries: u32,
    
    /// Number of peer switches during sync
    peer_switches: u32,
    
    pub fn init() SyncMetrics {
        const now = util.getTime();
        return .{
            .blocks_downloaded = 0,
            .bytes_downloaded = 0,
            .start_time = now,
            .last_progress_report = now,
            .total_retries = 0,
            .peer_switches = 0,
        };
    }
    
    /// Update metrics with new blocks
    pub fn updateBlocks(self: *SyncMetrics, block_count: u32, byte_count: u64) void {
        self.blocks_downloaded += block_count;
        self.bytes_downloaded += byte_count;
        
        print("ğŸ“ˆ [SYNC METRICS] Updated: {} blocks, {d:.1} MB total\n", .{
            self.blocks_downloaded,
            @as(f64, @floatFromInt(self.bytes_downloaded)) / 1024.0 / 1024.0,
        });
    }
    
    /// Calculate current download speed in blocks per second
    pub fn getBlocksPerSecond(self: *const SyncMetrics) f64 {
        const elapsed = util.getTime() - self.start_time;
        if (elapsed == 0) return 0.0;
        
        return @as(f64, @floatFromInt(self.blocks_downloaded)) / @as(f64, @floatFromInt(elapsed));
    }
    
    /// Calculate current download speed in MB per second
    pub fn getMBPerSecond(self: *const SyncMetrics) f64 {
        const elapsed = util.getTime() - self.start_time;
        if (elapsed == 0) return 0.0;
        
        const mb_downloaded = @as(f64, @floatFromInt(self.bytes_downloaded)) / 1024.0 / 1024.0;
        return mb_downloaded / @as(f64, @floatFromInt(elapsed));
    }
    
    /// Generate performance report
    pub fn reportPerformance(self: *SyncMetrics) void {
        const elapsed = util.getTime() - self.start_time;
        const blocks_per_sec = self.getBlocksPerSecond();
        const mb_per_sec = self.getMBPerSecond();
        
        print("ğŸ“Š [SYNC METRICS] Performance Report:\n", .{});
        print("   â€¢ Duration: {}s\n", .{elapsed});
        print("   â€¢ Blocks: {} ({d:.1}/s)\n", .{self.blocks_downloaded, blocks_per_sec});
        print("   â€¢ Data: {d:.1} MB ({d:.1} MB/s)\n", .{
            @as(f64, @floatFromInt(self.bytes_downloaded)) / 1024.0 / 1024.0,
            mb_per_sec,
        });
        print("   â€¢ Retries: {}\n", .{self.total_retries});
        print("   â€¢ Peer switches: {}\n", .{self.peer_switches});
        
        self.last_progress_report = util.getTime();
    }
    
    /// Check if it's time for a progress report
    pub fn shouldReportProgress(self: *const SyncMetrics) bool {
        const elapsed = util.getTime() - self.last_progress_report;
        return elapsed >= BATCH_CONFIG.PROGRESS_REPORT_INTERVAL;
    }
};

// ============================================================================
// ZSP-001 BATCH SYNC PROTOCOL IMPLEMENTATION
// ============================================================================

/// ZSP-001 Batch Synchronization Protocol
/// Main coordinator for high-performance batch blockchain synchronization
pub const BatchSyncProtocol = struct {
    /// Memory allocator for dynamic data structures
    allocator: Allocator,
    
    /// Current synchronization state
    sync_state: SyncState,
    
    /// Current sync peer (primary peer for this sync session)
    sync_peer: ?*Peer,
    
    /// Target height to synchronize to
    target_height: u32,
    
    /// Current blockchain height at sync start
    start_height: u32,
    
    /// Batch request tracking and coordination
    batch_tracker: BatchTracker,
    
    /// Out-of-order block queue for sequential processing
    pending_queue: PendingQueue,
    
    /// Performance metrics and monitoring
    metrics: SyncMetrics,
    
    /// Failed peers list for peer rotation
    failed_peers: std.ArrayList(*Peer),
    
    /// Dependency injection context for blockchain operations
    context: BatchSyncContext,
    
    const Self = @This();
    
    /// Synchronization states for the batch sync protocol
    pub const SyncState = enum {
        idle,           // Not synchronizing
        syncing,        // Active batch synchronization in progress
        applying,       // Applying validated blocks to blockchain
        complete,       // Synchronization completed successfully
        failed,         // Synchronization failed (can be retried)
        
        /// Check if sync is actively running
        pub fn isActive(self: SyncState) bool {
            return self == .syncing or self == .applying;
        }
        
        /// Check if sync can be started
        pub fn canStart(self: SyncState) bool {
            return self == .idle or self == .failed or self == .complete;
        }
    };
    
    /// Initialize the batch sync protocol
    pub fn init(allocator: Allocator, context: BatchSyncContext) Self {
        print("ğŸš€ [BATCH SYNC] Initializing ZSP-001 batch synchronization protocol\n", .{});
        print("ğŸ”§ [BATCH SYNC] Configuration: {} blocks/batch, {} concurrent batches\n", .{
            BATCH_CONFIG.BATCH_SIZE,
            BATCH_CONFIG.MAX_CONCURRENT_BATCHES,
        });
        
        return .{
            .allocator = allocator,
            .sync_state = .idle,
            .sync_peer = null,
            .target_height = 0,
            .start_height = 0,
            .batch_tracker = BatchTracker.init(allocator),
            .pending_queue = PendingQueue.init(allocator),
            .metrics = SyncMetrics.init(),
            .failed_peers = std.ArrayList(*Peer).init(allocator),
            .context = context,
        };
    }
    
    /// Clean up resources when sync protocol is destroyed
    pub fn deinit(self: *Self) void {
        print("ğŸ§¹ [BATCH SYNC] Cleaning up batch sync protocol resources\n", .{});
        
        self.batch_tracker.deinit();
        self.pending_queue.deinit();
        self.failed_peers.deinit();
        
        print("âœ… [BATCH SYNC] Cleanup completed\n", .{});
    }
    
    /// Start batch synchronization with a peer to a target height
    /// This is the main entry point for ZSP-001 batch sync
    pub fn startSync(self: *Self, peer: *Peer, target_height: u32) !void {
        print("ğŸš€ [BATCH SYNC] STARTING ZSP-001 BATCH SYNCHRONIZATION SESSION\n", .{});
        print("ğŸ“Š [BATCH SYNC] Target Peer: {any}\n", .{peer.address});
        print("ğŸ“Š [BATCH SYNC] Target Height: {} blocks\n", .{target_height});
        print("ğŸ“Š [BATCH SYNC] Current State: {}\n", .{self.sync_state});
        print("ğŸ“Š [BATCH SYNC] Batch Size: {} blocks per request\n", .{BATCH_CONFIG.BATCH_SIZE});
        print("ğŸ“Š [BATCH SYNC] Max Concurrent: {} batches\n", .{BATCH_CONFIG.MAX_CONCURRENT_BATCHES});
        print("ğŸ“Š [BATCH SYNC] Expected Performance: ~{}x faster than sequential\n", .{BATCH_CONFIG.BATCH_SIZE});
        
        // Validate sync can be started
        print("ğŸ” [BATCH SYNC] STEP 1: Validating sync prerequisites...\n", .{});
        if (!self.sync_state.canStart()) {
            print("âŒ [BATCH SYNC] STEP 1 FAILED: Cannot start sync in current state\n", .{});
            print("âŒ [BATCH SYNC] Current State: {} (expected: idle, failed, or complete)\n", .{self.sync_state});
            print("âŒ [BATCH SYNC] Sync session aborted\n", .{});
            return error.SyncAlreadyActive;
        }
        print("âœ… [BATCH SYNC] STEP 1 PASSED: Sync state validation successful\n", .{});
        
        // Get current blockchain height
        print("ğŸ” [BATCH SYNC] STEP 2: Querying current blockchain height...\n", .{});
        const current_height = try self.context.getHeight();
        print("âœ… [BATCH SYNC] STEP 2 COMPLETED: Current blockchain height = {}\n", .{current_height});
        
        // Validate sync is needed
        print("ğŸ” [BATCH SYNC] STEP 3: Calculating sync requirements...\n", .{});
        const blocks_to_sync = if (target_height > current_height) target_height - current_height else 0;
        const estimated_batches = (blocks_to_sync + BATCH_CONFIG.BATCH_SIZE - 1) / BATCH_CONFIG.BATCH_SIZE;
        print("ğŸ“Š [BATCH SYNC] Blocks to sync: {} ({} â†’ {})\n", .{blocks_to_sync, current_height, target_height});
        print("ğŸ“Š [BATCH SYNC] Estimated batches: {} (@ {} blocks each)\n", .{estimated_batches, BATCH_CONFIG.BATCH_SIZE});
        
        if (target_height <= current_height) {
            print("âœ… [BATCH SYNC] STEP 3 RESULT: Already synchronized - no sync needed\n", .{});
            print("â„¹ï¸ [BATCH SYNC] Local height {} >= target height {}\n", .{current_height, target_height});
            print("ğŸ [BATCH SYNC] Sync session completed immediately\n", .{});
            return;
        }
        print("âœ… [BATCH SYNC] STEP 3 PASSED: Sync required ({} blocks behind)\n", .{blocks_to_sync});
        
        // Initialize sync session
        print("ğŸ” [BATCH SYNC] STEP 4: Initializing sync session state...\n", .{});
        self.sync_state = .syncing;
        self.sync_peer = peer;
        self.target_height = target_height;
        self.start_height = current_height;
        self.metrics = SyncMetrics.init();
        print("âœ… [BATCH SYNC] STEP 4 COMPLETED: Session state initialized\n", .{});
        print("ğŸ“Š [BATCH SYNC] Session Details:\n", .{});
        print("   â””â”€ Sync State: {} â†’ {}\n", .{.idle, self.sync_state});
        print("   â””â”€ Start Height: {}\n", .{self.start_height});
        print("   â””â”€ Target Height: {}\n", .{self.target_height});
        print("   â””â”€ Sync Peer: {any}\n", .{peer.address});
        
        // Configure batch tracker for this sync session
        print("ğŸ” [BATCH SYNC] STEP 5: Configuring batch tracker...\n", .{});
        self.batch_tracker.next_batch_start = current_height + 1;
        print("âœ… [BATCH SYNC] STEP 5 COMPLETED: Batch tracker configured (next start: {})\n", .{self.batch_tracker.next_batch_start});
        self.batch_tracker.completed_height = current_height;
        
        const blocks_needed = target_height - current_height;
        print("ğŸ“ˆ [BATCH SYNC] Sync initialized: {} blocks needed\n", .{blocks_needed});
        print("ğŸ”§ [BATCH SYNC] Expected performance: up to {}x faster than sequential sync\n", .{
            BATCH_CONFIG.BATCH_SIZE
        });
        
        // Start the batch download pipeline
        print("ğŸ” [BATCH SYNC] STEP 6: Starting batch request pipeline...\n", .{});
        try self.fillBatchPipeline();
        print("âœ… [BATCH SYNC] STEP 6 COMPLETED: Pipeline started successfully\n", .{});
        
        print("ğŸ‰ [BATCH SYNC] ZSP-001 SYNC SESSION ACTIVE!\n", .{});
    }
    
    /// Fill the batch request pipeline with concurrent requests
    /// Ensures optimal network utilization by maintaining multiple active requests
    fn fillBatchPipeline(self: *Self) !void {
        print("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        print("ğŸ”„ [BATCH PIPELINE] FILLING BATCH REQUEST PIPELINE\n", .{});
        print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n", .{});
        
        var batches_launched: u32 = 0;
        const max_batches = BATCH_CONFIG.MAX_CONCURRENT_BATCHES;
        const current_active = self.batch_tracker.active_batches.count();
        const can_launch = max_batches - @as(u32, @intCast(current_active));
        
        print("ğŸ“Š [BATCH PIPELINE] Current state:\n", .{});
        print("   â””â”€ Active batches: {} / {}\n", .{current_active, max_batches});
        print("   â””â”€ Can launch: {} more batches\n", .{can_launch});
        print("   â””â”€ Next batch starts at height: {}\n", .{self.batch_tracker.next_batch_start});
        print("   â””â”€ Target height: {}\n", .{self.target_height});
        
        if (can_launch == 0) {
            print("âš ï¸ [BATCH PIPELINE] Pipeline full - no new batches can be launched\n", .{});
            return;
        }
        
        // Launch batches up to concurrent limit
        print("ğŸš€ [BATCH PIPELINE] Launching batch requests...\n", .{});
        while (self.batch_tracker.canRequestMoreBatches() and 
               self.batch_tracker.next_batch_start <= self.target_height) {
            
            const batch_start = self.batch_tracker.next_batch_start;
            print("ğŸ” [BATCH PIPELINE] Requesting batch #{} (height {})\n", .{batches_launched + 1, batch_start});
            try self.requestNextBatch();
            batches_launched += 1;
            print("âœ… [BATCH PIPELINE] Batch #{} request sent\n", .{batches_launched});
        }
        
        print("\nğŸ“Š [BATCH PIPELINE] PIPELINE FILL COMPLETE\n", .{});
        print("   â””â”€ Batches launched this round: {}\n", .{batches_launched});
        print("   â””â”€ Total active batches: {}\n", .{self.batch_tracker.active_batches.count()});
        print("   â””â”€ Next batch start: {}\n", .{self.batch_tracker.next_batch_start});
        
        if (batches_launched == 0) {
            print("âš ï¸ [BATCH SYNC] No batches could be launched - checking completion\n", .{});
            try self.checkSyncCompletion();
        }
    }
    
    /// Request the next batch of blocks from the sync peer
    /// Creates and sends a ZSP-001 compliant height-encoded batch request
    fn requestNextBatch(self: *Self) !void {
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n", .{});
        print("â”‚                  BATCH REQUEST PREPARATION                      â”‚\n", .{});
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n", .{});
        
        // Validate sync peer availability
        print("ğŸ” [BATCH REQUEST] STEP 1: Validating sync peer...\n", .{});
        const peer = self.sync_peer orelse {
            print("âŒ [BATCH REQUEST] STEP 1 FAILED: No sync peer available\n", .{});
            return error.NoPeerAvailable;
        };
        print("âœ… [BATCH REQUEST] STEP 1 PASSED: Sync peer {} available\n", .{peer.address});
        
        // Calculate batch parameters
        print("ğŸ” [BATCH REQUEST] STEP 2: Calculating batch parameters...\n", .{});
        const start_height = self.batch_tracker.next_batch_start;
        const remaining_blocks = self.target_height - start_height + 1;
        const batch_size = @min(BATCH_CONFIG.BATCH_SIZE, remaining_blocks);
        const end_height = start_height + batch_size - 1;
        
        print("ğŸ“Š [BATCH REQUEST] Batch calculation results:\n", .{});
        print("   â””â”€ Start height: {}\n", .{start_height});
        print("   â””â”€ End height: {}\n", .{end_height});
        print("   â””â”€ Batch size: {} blocks\n", .{batch_size});
        print("   â””â”€ Remaining total: {} blocks\n", .{remaining_blocks});
        print("   â””â”€ Target height: {}\n", .{self.target_height});
        print("âœ… [BATCH REQUEST] STEP 2 COMPLETED: Parameters calculated\n", .{});
        
        // Create batch request tracking
        print("ğŸ” [BATCH REQUEST] STEP 3: Creating batch tracking...\n", .{});
        const batch_request = BatchRequest.init(start_height, batch_size, peer);
        var desc_buf: [64]u8 = [_]u8{0} ** 64;
        const batch_desc = batch_request.describe(&desc_buf);
        print("âœ… [BATCH REQUEST] STEP 3 COMPLETED: Batch tracker created\n", .{});
        print("ğŸ“Š [BATCH REQUEST] Batch details: {s}\n", .{batch_desc});
        
        // Send ZSP-001 height-encoded batch request
        print("ğŸ” [BATCH REQUEST] STEP 4: Sending ZSP-001 batch request...\n", .{});
        try self.sendBatchRequest(peer, start_height, batch_size);
        print("âœ… [BATCH REQUEST] STEP 4 COMPLETED: Request transmitted to peer\n", .{});
        
        // Track the batch request
        print("ğŸ” [BATCH REQUEST] STEP 5: Adding to batch tracker...\n", .{});
        try self.batch_tracker.addBatch(batch_request);
        print("âœ… [BATCH REQUEST] STEP 5 COMPLETED: Batch added to tracker\n", .{});
        
        // Update next batch start for pipeline
        print("ğŸ” [BATCH REQUEST] STEP 6: Updating pipeline state...\n", .{});
        const old_next_start = self.batch_tracker.next_batch_start;
        self.batch_tracker.next_batch_start = start_height + batch_size;
        print("âœ… [BATCH REQUEST] STEP 6 COMPLETED: Next batch start: {} â†’ {}\n", .{
            old_next_start, self.batch_tracker.next_batch_start
        });
        
        print("\nğŸ‰ [BATCH REQUEST] BATCH REQUEST SUCCESSFULLY DISPATCHED!\n", .{});
        print("ğŸ“Š [BATCH REQUEST] Summary: {s} sent to {any}\n", .{batch_desc, peer.address});
    }
    
    /// Send ZSP-001 compliant height-encoded batch request to peer
    /// Uses the 0xDEADBEEF magic marker for backward compatibility
    fn sendBatchRequest(self: *Self, peer: *Peer, start_height: u32, batch_size: u32) !void {
        print("\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n", .{});
        print("â”‚                ZSP-001 BATCH REQUEST ENCODING                   â”‚\n", .{});
        print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n", .{});
        
        print("ğŸ” [ZSP-001 ENCODE] STEP 1: Allocating hash array ({} blocks)...\n", .{batch_size});
        const encoded_hashes = try self.allocator.alloc([32]u8, batch_size);
        defer self.allocator.free(encoded_hashes);
        print("âœ… [ZSP-001 ENCODE] STEP 1 COMPLETED: {} hash slots allocated\n", .{batch_size});
        
        // Encode each height using ZSP-001 specification
        print("ğŸ” [ZSP-001 ENCODE] STEP 2: Encoding heights with 0xDEADBEEF magic...\n", .{});
        print("ğŸ“Š [ZSP-001 ENCODE] ZSP-001 format: [height:4][0xDEADBEEF:4][zeros:24]\n", .{});
        
        for (0..batch_size) |i| {
            const height = start_height + @as(u32, @intCast(i));
            encoded_hashes[i] = encodeHeightAsHash(height);
            
            print("   â””â”€ Height {} â†’ {s}...{s}\n", .{
                height,
                std.fmt.fmtSliceHexLower(encoded_hashes[i][0..4]), // Height bytes
                std.fmt.fmtSliceHexLower(encoded_hashes[i][4..8]), // Magic marker
            });
        }
        print("âœ… [ZSP-001 ENCODE] STEP 2 COMPLETED: All {} heights encoded\n", .{batch_size});
        
        // Send batch request using existing peer protocol
        print("ğŸ” [ZSP-001 ENCODE] STEP 3: Transmitting batch to peer {any}...\n", .{peer.address});
        try peer.sendGetBlocks(encoded_hashes);
        print("âœ… [ZSP-001 ENCODE] STEP 3 COMPLETED: Batch transmitted via GetBlocks\n", .{});
        
        print("\nğŸš€ [ZSP-001 ENCODE] BATCH REQUEST SUCCESSFULLY SENT!\n", .{});
        print("ğŸ“Š [ZSP-001 ENCODE] Summary: {} height-encoded blocks requested from {any}\n", .{
            batch_size, peer.address
        });
    }
    
    /// Handle incoming batch of blocks from peer
    /// Processes blocks and manages the sync pipeline
    pub fn handleBatchBlocks(self: *Self, blocks: []const Block, start_height: u32) !void {
        print("ğŸ“¥ [BATCH RECEIVE] PROCESSING INCOMING BATCH BLOCKS\n", .{});
        print("ğŸ“Š [BATCH RECEIVE] Batch details:\n", .{});
        print("   â””â”€ Block count: {} blocks\n", .{blocks.len});
        print("   â””â”€ Start height: {}\n", .{start_height});
        print("   â””â”€ End height: {}\n", .{start_height + @as(u32, @intCast(blocks.len)) - 1});
        print("   â””â”€ Current sync state: {}\n", .{self.sync_state});
        
        // Validate we're expecting this batch
        print("ğŸ” [BATCH RECEIVE] STEP 1: Validating batch expectation...\n", .{});
        if (!self.batch_tracker.active_batches.contains(start_height)) {
            print("âŒ [BATCH RECEIVE] STEP 1 FAILED: Unexpected batch received\n", .{});
            print("âŒ [BATCH RECEIVE] Height {} not in active requests\n", .{start_height});
            print("ğŸ“Š [BATCH RECEIVE] Active batches:\n", .{});
            var iterator = self.batch_tracker.active_batches.iterator();
            while (iterator.next()) |entry| {
                print("   â””â”€ Height: {}\n", .{entry.key_ptr.*});
            }
            return;
        }
        print("âœ… [BATCH RECEIVE] STEP 1 PASSED: Batch was expected and requested\n", .{});
        
        // Remove from active batch tracking
        print("ğŸ” [BATCH RECEIVE] STEP 2: Updating batch tracker...\n", .{});
        const was_removed = self.batch_tracker.removeBatch(start_height);
        if (was_removed) {
            print("âœ… [BATCH RECEIVE] STEP 2 COMPLETED: Batch removed from active tracker\n", .{});
        } else {
            print("âš ï¸ [BATCH RECEIVE] STEP 2 WARNING: Batch not found in tracker\n", .{});
        }
        print("ğŸ“Š [BATCH RECEIVE] Active batches remaining: {}\n", .{self.batch_tracker.active_batches.count()});
        
        // Add blocks to pending queue for sequential processing
        print("ğŸ” [BATCH RECEIVE] STEP 3: Storing blocks in pending queue...\n", .{});
        var bytes_received: u64 = 0;
        var blocks_stored: u32 = 0;
        
        for (blocks, 0..) |block, i| {
            const block_height = start_height + @as(u32, @intCast(i));
            
            // Estimate block size for metrics (simplified)
            bytes_received += @sizeOf(Block);
            
            // Store block in pending queue
            const block_copy = try block.clone(self.allocator);
            try self.pending_queue.addBlock(block_height, block_copy);
            blocks_stored += 1;
            
            if (i < 3 or i >= blocks.len - 3) { // Log first 3 and last 3
                print("   â””â”€ Block {} stored in queue\n", .{block_height});
            } else if (i == 3) {
                print("   â””â”€ ... ({} blocks) ...\n", .{blocks.len - 6});
            }
        }
        print("âœ… [BATCH RECEIVE] STEP 3 COMPLETED: {} blocks stored ({} bytes)\n", .{
            blocks_stored, bytes_received
        });
        
        // Update performance metrics
        print("ğŸ” [BATCH RECEIVE] STEP 4: Updating performance metrics...\n", .{});
        self.metrics.updateBlocks(@intCast(blocks.len), bytes_received);
        print("âœ… [BATCH RECEIVE] STEP 4 COMPLETED: Metrics updated\n", .{});
        print("ğŸ“Š [BATCH RECEIVE] Current metrics:\n", .{});
        print("   â””â”€ Total blocks: {}\n", .{self.metrics.blocks_received});
        print("   â””â”€ Total bytes: {}\n", .{self.metrics.bytes_received});
        print("   â””â”€ Blocks/sec: {d:.2}\n", .{self.metrics.getBlocksPerSecond()});
        
        // Process any sequential blocks that are now available
        print("ğŸ” [BATCH RECEIVE] STEP 5: Processing sequential blocks...\n", .{});
        try self.processSequentialBlocks();
        print("âœ… [BATCH RECEIVE] STEP 5 COMPLETED: Sequential processing done\n", .{});
        
        // Continue batch pipeline if sync not complete
        try self.fillBatchPipeline();
        
        // Report progress if needed
        if (self.metrics.shouldReportProgress()) {
            self.metrics.reportPerformance();
        }
    }
    
    /// Process blocks sequentially from the pending queue
    /// Ensures blocks are applied to blockchain in correct order
    fn processSequentialBlocks(self: *Self) !void {
        print("ğŸ”„ [BATCH SYNC] Processing sequential blocks from pending queue\n", .{});
        
        var blocks_processed: u32 = 0;
        var next_expected = self.batch_tracker.completed_height + 1;
        
        // Process all available sequential blocks
        while (self.pending_queue.getNextBlock(next_expected)) |block| {
            print("ğŸ“ [BATCH SYNC] Applying block {} to blockchain\n", .{next_expected});
            
            // Apply block using dependency injection
            self.context.applyBlock(block) catch |err| {
                print("âŒ [BATCH SYNC] Failed to apply block {}: {}\n", .{next_expected, err});
                
                // Clean up the block
                var owned_block = block;
                owned_block.deinit(self.allocator);
                
                // Fail the sync on block application error
                self.failSync("Block application failed");
                return err;
            };
            
            // Clean up the block after successful application
            var owned_block = block;
            owned_block.deinit(self.allocator);
            
            // Update tracking
            self.batch_tracker.completed_height = next_expected;
            next_expected += 1;
            blocks_processed += 1;
            
            print("âœ… [BATCH SYNC] Block {} applied successfully\n", .{next_expected - 1});
        }
        
        if (blocks_processed > 0) {
            print("ğŸ“Š [BATCH SYNC] Processed {} sequential blocks (completed: {})\n", .{
                blocks_processed, self.batch_tracker.completed_height
            });
            
            // Check if sync is now complete
            try self.checkSyncCompletion();
        }
    }
    
    /// Check if synchronization is complete and finalize if so
    fn checkSyncCompletion(self: *Self) !void {
        const completed = self.batch_tracker.completed_height;
        const target = self.target_height;
        
        print("ğŸ” [BATCH SYNC] Checking completion: {}/{} blocks\n", .{completed, target});
        
        // Check if all blocks have been processed
        if (completed >= target and 
            self.batch_tracker.active_batches.count() == 0 and
            self.pending_queue.size() == 0) {
            
            print("ğŸ‰ [BATCH SYNC] Synchronization completed successfully!\n", .{});
            
            // Generate final performance report
            self.metrics.reportPerformance();
            
            // Calculate performance improvement
            const total_blocks = target - self.start_height;
            const estimated_sequential_time = total_blocks; // 1 second per block estimate
            const actual_time = util.getTime() - self.metrics.start_time;
            const improvement = if (actual_time > 0) 
                @as(f64, @floatFromInt(estimated_sequential_time)) / @as(f64, @floatFromInt(actual_time))
            else 
                1.0;
            
            print("ğŸ“ˆ [BATCH SYNC] Performance improvement: {d:.1}x faster than sequential\n", .{
                improvement
            });
            
            // Mark sync as complete
            self.sync_state = .complete;
            self.sync_peer = null;
            
            print("âœ… [BATCH SYNC] ZSP-001 batch synchronization completed\n", .{});
        }
    }
    
    /// Handle sync timeout and stalled requests
    /// Implements retry logic and peer failover as specified in ZSP-001
    pub fn handleTimeouts(self: *Self) !void {
        if (!self.sync_state.isActive()) return;
        
        // Get timed-out batches
        var timed_out_batches = try self.batch_tracker.getTimedOutBatches(self.allocator);
        defer timed_out_batches.deinit();
        
        if (timed_out_batches.items.len == 0) return;
        
        print("â° [BATCH SYNC] Handling {} timed-out batches\n", .{timed_out_batches.items.len});
        
        // Process each timed-out batch
        for (timed_out_batches.items) |*batch| {
            // Remove from tracking
            _ = self.batch_tracker.removeBatch(batch.start_height);
            
            // Check retry limit
            if (batch.retry_count >= BATCH_CONFIG.MAX_BATCH_RETRIES) {
                print("âŒ [BATCH SYNC] Batch {} exceeded retry limit, switching peer\n", .{
                    batch.start_height
                });
                
                try self.switchSyncPeer();
                self.metrics.peer_switches += 1;
                
                // Reset retry count with new peer
                batch.retry_count = 0;
            }
            
            // Retry the batch request
            batch.retry_count += 1;
            batch.timestamp = util.getTime();
            self.metrics.total_retries += 1;
            
            print("ğŸ”„ [BATCH SYNC] Retrying batch {} (attempt {})\n", .{
                batch.start_height, batch.retry_count
            });
            
            // Send retry request
            if (self.sync_peer) |peer| {
                try self.sendBatchRequest(peer, batch.start_height, batch.batch_size);
                try self.batch_tracker.addBatch(batch.*);
            }
        }
    }
    
    /// Switch to a new peer for sync (peer failover mechanism)
    /// Essential for reliability in distributed network environment
    fn switchSyncPeer(self: *Self) !void {
        print("ğŸ”„ [BATCH SYNC] Switching sync peer for failover\n", .{});
        
        // Add current peer to failed list if exists
        if (self.sync_peer) |failed_peer| {
            try self.failed_peers.append(failed_peer);
            print("ğŸš« [BATCH SYNC] Added peer to failed list (total: {})\n", .{
                self.failed_peers.items.len
            });
        }
        
        // Find a new peer (this would integrate with peer manager)
        // For now, we'll mark as failed - real implementation would get from network
        const new_peer = self.context.getNextPeer() orelse {
            print("âŒ [BATCH SYNC] No alternative peers available\n", .{});
            self.failSync("No alternative peers for failover");
            return;
        };
        
        self.sync_peer = new_peer;
        print("âœ… [BATCH SYNC] Switched to new peer for sync continuation\n", .{});
    }
    
    /// Fail the synchronization with a reason
    /// Cleans up state and allows for future retry attempts
    fn failSync(self: *Self, reason: []const u8) void {
        print("âŒ [BATCH SYNC] Sync failed: {s}\n", .{reason});
        
        self.sync_state = .failed;
        self.sync_peer = null;
        
        // Clean up active state but preserve failed peers for future attempts
        self.batch_tracker.active_batches.clearRetainingCapacity();
        self.pending_queue.deinit();
        self.pending_queue = PendingQueue.init(self.allocator);
        
        print("ğŸ§¹ [BATCH SYNC] Sync state cleaned up for potential retry\n", .{});
    }
    
    /// Get current sync state
    pub fn getSyncState(self: *const Self) SyncState {
        return self.sync_state;
    }
    
    /// Get sync progress as percentage
    pub fn getProgress(self: *const Self) f64 {
        if (self.target_height <= self.start_height) return 100.0;
        
        const total_blocks = self.target_height - self.start_height;
        const completed_blocks = self.batch_tracker.completed_height - self.start_height;
        
        return (@as(f64, @floatFromInt(completed_blocks)) / @as(f64, @floatFromInt(total_blocks))) * 100.0;
    }
    
    /// Get detailed sync status for monitoring
    pub fn getStatus(self: *const Self) void {
        print("ğŸ“Š [BATCH SYNC] Status Report:\n", .{});
        print("   â€¢ State: {}\n", .{self.sync_state});
        print("   â€¢ Progress: {d:.1}%\n", .{self.getProgress()});
        print("   â€¢ Completed: {}/{}\n", .{self.batch_tracker.completed_height, self.target_height});
        
        self.batch_tracker.getStatus();
        self.pending_queue.getStatus();
        
        if (self.sync_state.isActive()) {
            self.metrics.reportPerformance();
        }
    }
};

// ============================================================================
// ZSP-001 UTILITY FUNCTIONS  
// ============================================================================

/// Encode a block height as a 32-byte hash using ZSP-001 specification
/// Uses 0xDEADBEEF magic marker for backward compatibility with hash-based requests
fn encodeHeightAsHash(height: u32) [32]u8 {
    var hash: [32]u8 = [_]u8{0} ** 32;
    
    // ZSP-001: Magic marker in first 4 bytes
    std.mem.writeInt(u32, hash[0..4], HEIGHT_REQUEST_MAGIC, .little);
    
    // Height in next 4 bytes
    std.mem.writeInt(u32, hash[4..8], height, .little);
    
    // Remaining bytes stay zero for consistency
    
    return hash;
}

/// Decode height from ZSP-001 encoded hash
/// Returns null if not a valid height-encoded hash
fn decodeHashAsHeight(hash: [32]u8) ?u32 {
    const magic = std.mem.readInt(u32, hash[0..4], .little);
    if (magic != HEIGHT_REQUEST_MAGIC) {
        return null; // Not a height-encoded request
    }
    
    return std.mem.readInt(u32, hash[4..8], .little);
}

/// Check if a hash represents a height-encoded request
pub fn isHeightEncodedRequest(hash: [32]u8) bool {
    return decodeHashAsHeight(hash) != null;
}

// ============================================================================
// ZSP-001 DEPENDENCY INJECTION INTERFACE
// ============================================================================

/// Dependency injection context for batch sync protocol
/// Allows the sync protocol to interact with blockchain without tight coupling
pub const BatchSyncContext = struct {
    /// Get current blockchain height
    getHeight: *const fn() anyerror!u32,
    
    /// Apply a validated block to the blockchain
    applyBlock: *const fn(block: Block) anyerror!void,
    
    /// Get next available peer for sync (returns null if none available)
    getNextPeer: *const fn() ?*Peer,
    
    /// Validate a block before applying (optional, can be no-op)
    validateBlock: *const fn(block: Block, height: u32) anyerror!bool,
};

// ============================================================================
// ZSP-001 TESTING AND VALIDATION
// ============================================================================

/// Test height encoding/decoding functions
pub fn testHeightEncoding() !void {
    print("ğŸ§ª [BATCH SYNC] Testing ZSP-001 height encoding\n", .{});
    
    const test_heights = [_]u32{ 0, 1, 1000, 65535, 1000000 };
    
    for (test_heights) |height| {
        const encoded = encodeHeightAsHash(height);
        const decoded = decodeHashAsHeight(encoded) orelse {
            print("âŒ Failed to decode height {}\n", .{height});
            return error.DecodingFailed;
        };
        
        if (decoded != height) {
            print("âŒ Height mismatch: {} != {}\n", .{height, decoded});
            return error.HeightMismatch;
        }
        
        if (!isHeightEncodedRequest(encoded)) {
            print("âŒ Height {} not recognized as encoded request\n", .{height});
            return error.EncodingNotRecognized;
        }
    }
    
    print("âœ… [BATCH SYNC] Height encoding tests passed\n", .{});
}

/// Test batch tracker functionality
pub fn testBatchTracker() !void {
    print("ğŸ§ª [BATCH SYNC] Testing batch tracker\n", .{});
    
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();
    
    var tracker = BatchTracker.init(allocator);
    defer tracker.deinit();
    
    // Test basic operations
    if (!tracker.canRequestMoreBatches()) {
        return error.ShouldAllowMoreBatches;
    }
    
    print("âœ… [BATCH SYNC] Batch tracker tests passed\n", .{});
}

/// Comprehensive ZSP-001 protocol test suite
pub fn runTests() !void {
    print("ğŸ§ª [BATCH SYNC] Running ZSP-001 protocol test suite\n", .{});
    
    try testHeightEncoding();
    try testBatchTracker();
    
    print("âœ… [BATCH SYNC] All ZSP-001 tests passed successfully\n", .{});
}